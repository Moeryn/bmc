This weekend ended up being quite productive. It actually already started during
the past week by an exercise in learning about [music21](http://web.mit.edu/music21/).
After I found (and filed) a few bugs related to music21's braille transcription
abilities, I began work on enabling BMC to parse at least a bit of what
music21 can generate.  There is still work to do regarding the section
formatting that music21 uses, but short excerpts of braille music can
now be generated by music21 and parsed and validated by BMC.  This might end
up being an interesting tools for developers working on braille transcription
software, since BMC can now be used as a sort of proof-reader.

This whole new realm of possibilities is now being explored in an optional testsuite for BMC, which is being run when music21 is installed.
It currently contains just three little melodies, but it can easily
grow, and will be extended in the future.

During evaluation of the result of one of these test melodies, I realized
(late, but still) that we should really map notegroups to beaming.
After a bit of thinking, it turned out to be lots easier then anticipated.
Apparently, some parts of BMC are really well designed, that was made
apparent by the ease of this addition.

BMC's LilyPond output now places beams over notegroups in the braille input.
This is an important improvement, as it links up two aspects
of tactile and visual notation, that are quite different in how they
are implemented in both worlds, but still do express a fundamentally equal concept.

I also took a bit of time to rework test.cpp such that it doesn't do things unnecessarily twice.
We have a bit more strict testing now, and the testsuite runtime dropped about 25%.
This refactoring was long in order.

All in all, this was a wonderful weekend for BMC development.
